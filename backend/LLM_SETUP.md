# Configura√ß√£o do LLM (Claude) para Sugest√µes Inteligentes

## Vis√£o Geral

O sistema AI Concierge agora suporta gera√ß√£o de sugest√µes usando Claude (Anthropic) para criar sugest√µes mais naturais, contextuais e personalizadas.

## Como Funciona

### Sistema H√≠brido
O sistema opera em modo h√≠brido:
1. **An√°lise baseada em regras**: Para sugest√µes cr√≠ticas e sens√≠veis ao tempo (anivers√°rios, pagamentos recorrentes)
2. **An√°lise por LLM**: Para sugest√µes criativas e contextuais baseadas em padr√µes complexos

### Fluxo de Gera√ß√£o

```
Usu√°rio
  ‚Üì
Coleta de Contexto
  ‚îú‚îÄ Perfil (nome, idade, prefer√™ncias)
  ‚îú‚îÄ Transa√ß√µes (√∫ltimos 90 dias)
  ‚îî‚îÄ Sugest√µes anteriores (aceitas/rejeitadas)
  ‚Üì
An√°lise H√≠brida
  ‚îú‚îÄ Regras: Datas importantes sempre processadas
  ‚îî‚îÄ LLM: An√°lise contextual profunda
  ‚Üì
Deduplica√ß√£o e Prioriza√ß√£o
  ‚Üì
Sugest√µes Personalizadas
```

## Configura√ß√£o

### 1. Obter API Key da Anthropic

1. Acesse https://console.anthropic.com/
2. Crie uma conta ou fa√ßa login
3. V√° para "API Keys"
4. Crie uma nova chave
5. Copie a chave (come√ßa com `sk-ant-`)

### 2. Configurar o Backend

1. Copie o arquivo de exemplo:
```bash
cp .env.example .env
```

2. Edite o arquivo `.env` e adicione sua API key:
```env
ANTHROPIC_API_KEY="sk-ant-api03-..."  # Sua chave aqui
```

3. Configure o modelo (opcional):
```env
# Op√ß√µes de modelo (Janeiro 2025):
LLM_MODEL="claude-opus-4-20250514"       # Opus 4 - Mais avan√ßado
LLM_MODEL="claude-sonnet-4-20250514"     # Sonnet 4 - Muito capaz
LLM_MODEL="claude-3-7-sonnet-20250219"   # Sonnet 3.7 - RECOMENDADO (padr√£o)
LLM_MODEL="claude-3-5-haiku-20241022"    # Haiku 3.5 - Mais econ√¥mico
```

4. Ajuste par√¢metros (opcional):
```env
LLM_MAX_TOKENS=1000        # Tamanho m√°ximo da resposta
LLM_TEMPERATURE=0.7        # Criatividade (0.0 a 1.0)
USE_LLM_FOR_SUGGESTIONS=True  # False para usar apenas regras
```

### 3. Reiniciar o Servidor

```bash
# Parar o servidor (Ctrl+C)
# Reiniciar
uvicorn app.main:app --reload
```

## Exemplos de Sugest√µes

### Com Regras (Sistema Anterior)
```
"O anivers√°rio de Maria est√° chegando (15/08). Gostaria de fazer uma reserva em algum restaurante especial?"
```

### Com LLM (Claude)
```
"Bruno, o anivers√°rio da Maria est√° chegando dia 15! üéâ Notei que voc√™s adoram o Fasano - 
j√° foram l√° 3 vezes em datas especiais. Que tal reservar uma mesa para o jantar? 
Posso tamb√©m sugerir aquela floricultura do Shopping Iguatemi onde voc√™ comprou 
o √∫ltimo buqu√™."
```

## Monitoramento

### Logs do Sistema
O sistema registra:
- Quando usa LLM vs regras
- Tempo de resposta da API
- Erros e fallbacks
- Sugest√µes geradas

### Verificar se est√° funcionando:
```python
# No backend, check logs para:
"Generated 5 new suggestions using Claude"
"Error generating LLM suggestions: [erro]"
"Falling back to rule-based suggestions"
```

## Custos

### Estimativa de Uso
- **Por usu√°rio**: ~500-1000 tokens por an√°lise
- **Frequ√™ncia**: Configur√°vel (padr√£o: a cada 6 horas)
- **Custo m√©dio**: ~$0.002-0.005 por an√°lise

### Modelos Dispon√≠veis (Janeiro 2025)

#### Novos Modelos (Recomendados)
- **Claude Opus 4** (`claude-opus-4-20250514`): Mais capaz, maior custo
- **Claude Sonnet 4** (`claude-sonnet-4-20250514`): Muito capaz, custo alto
- **Claude Sonnet 3.7** (`claude-3-7-sonnet-20250219`): **RECOMENDADO** - Excelente equil√≠brio
- **Claude Haiku 3.5** (`claude-3-5-haiku-20241022`): Mais r√°pido, menor custo

#### Compara√ß√£o de Capacidades
- **Opus 4**: Para an√°lises complexas e sugest√µes muito sofisticadas
- **Sonnet 3.7**: Ideal para uso di√°rio - r√°pido, inteligente e econ√¥mico
- **Haiku 3.5**: Para alto volume com or√ßamento limitado

## Troubleshooting

### API Key n√£o funciona
```
Error: ANTHROPIC_API_KEY not configured
```
- Verifique se a chave est√° no `.env`
- Confirme que n√£o h√° espa√ßos extras
- Teste se o servidor carregou o .env

### Timeout ou erro de rede
```
Error calling Claude API: timeout
```
- Verifique conex√£o com internet
- API da Anthropic pode estar lenta
- Sistema automaticamente usa regras como fallback

### Sugest√µes gen√©ricas
- Ajuste `LLM_TEMPERATURE` para 0.8-0.9
- Verifique se h√° dados suficientes do usu√°rio
- Mais transa√ß√µes = melhor contexto

## Seguran√ßa

### Dados Enviados
O sistema envia apenas:
- Nome e idade (sem documentos)
- Padr√µes de transa√ß√£o (sem detalhes banc√°rios)
- Prefer√™ncias gerais
- Hist√≥rico de sugest√µes

### Dados N√ÉO Enviados
- Senhas ou tokens
- N√∫meros de cart√£o
- Documentos pessoais
- Dados banc√°rios completos

## Desabilitar LLM

Para voltar ao sistema baseado em regras:
```env
USE_LLM_FOR_SUGGESTIONS=False
```

Ou remova a API key:
```env
ANTHROPIC_API_KEY=""
```